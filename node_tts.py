# coding=utf-8
# åœ¨çº¿TTSèŠ‚ç‚¹
import sys
import base64
import json
from time import sleep
#1.æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–,é…ç½®logç­‰çº§
from utility import mlogging
mlogging.logger_config('tts', mlogging.INFO, False)

from transformers import pipeline
from mq_base_node import MqBaseNode, mq_close
import websocket
# from utility.keyboard import KBHit
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("tts")

from mq_base_node import MqBaseNode, mq_close
from tts.volc_tts import VolcTTS
from tts.xfai_tts import XFaiTTS
# Load sentiment model
sentiment_analyzer = pipeline("sentiment-analysis")

class TTSNode(MqBaseNode):
    """ttsèŠ‚ç‚¹
    """
    def __init__(self, config: dict):
        """åˆå§‹åŒ–
        Args:
            config  appå‚æ•°é…ç½®ä¿¡æ¯
        """
        # rabbitmqåˆå§‹åŒ–
        super().__init__(config['rabbitmq']) 
        # rabbitmqæ¥æ”¶ç¼“å†²é˜Ÿåˆ—æœ€å¤§é•¿åº¦
        self.set_que_max_len(5000)

        self.tts_config = config['tts']
        self.audio_format = self.tts_config['common']['audio']['codec']
        self.audio_samplerate = self.tts_config['common']['audio']['samplerate']
        self.audio_channels = self.tts_config['common']['audio']['channels']

        # é”®ç›˜æ§åˆ¶
        # self.keyboard = KBHit()
        self.node_exit = False

        # ttså®ä¾‹
        self.tts = None
        service = self.tts_config['service']
        if service == 'volc':
            self.tts = VolcTTS(config=self.tts_config)
        elif service == 'xfai':
            self.tts = XFaiTTS(config=self.tts_config)
        else:
            logger.error('invalid tts service: {}'.format(service))

        # å•æ¬¡TTSè¯·æ±‚æ–‡æœ¬é•¿åº¦é™åˆ¶ä¸º 1024 å­—èŠ‚(ä¸è¦è¶…å‡ºæœåŠ¡å•†APIè¦æ±‚çš„é™åˆ¶)
        self._tts_text_bytes_max = 1024

        # éŸ³é¢‘æ•°æ®ç¼“å†²åŒºå¤§å°(å›ºå®š,éœ€è¦å’Œç¡¬ä»¶APIåŒ¹é…)
        self._audio_frame_length = 512
        self._audio_frame_buff = b''

        # èŠå¤©è¯­å¥ç¼“å†²
        self.chat_answers = ''
        # å‰nå¥ç›´æ¥åˆæˆï¼Œä¸ç­‰å¾…
        self.direct_n = self.tts_config['common']['direct_n']

        # æœ¬è½®èŠå¤©ID
        self.chat_id = 0
        # å·²å–æ¶ˆçš„èŠå¤©ID
        self.cancel_chat_id = -1

    @mq_close
    def close(self):
        """å…³é—­èŠ‚ç‚¹
        """
        self.tts.close()
        self.node_exit = True
        logger.info('app exit')

    def create_response_msg(self, chat_id: int, chat_end: int, seg_end: int, text=None, audio=None):
        """åˆ›å»ºå“åº”æ¶ˆæ¯
        Args:
            chat_id: æœ¬è½®èŠå¤©ID
            chat_end: 1 or 0, å“åº”å®Œå…¨ç»“æŸ
            seg_end: 1 or 0, ä¸€æ®µç»“æŸ
            text:  æœ¬æ¬¡åˆæˆçš„æ–‡æœ¬(ä¸€æ¬¡è¯·æ±‚çš„å®Œæ•´æ–‡æœ¬ï¼Œå¹¶æœªå¯¹åº”è¯­éŸ³ç‰‡æ®µ)
            audio: åˆæˆçš„éŸ³é¢‘æ•°æ® 
        Note:
            ç¡®ä¿æ•´ä½“æ•°æ®åŒ…é•¿åº¦ä¸è¶…è¿‡ç¡¬ä»¶è®¾å®šå€¼,é»˜è®¤(2048)
        """
        data_obj = {
            'node': self.node_name,
            'topic': "chat/response",
            'type': "json",
            'data':{
                'chat_id': chat_id,  
                'chat_end': chat_end,  
                'seg_end': seg_end,  
            }    
        }
        if text is not None:
            ## TODO: æœªé˜²æ­¢åŒ…å¤§å°è¶…å‡ºæœ€å¤§å€¼,éœ€è¦æ§åˆ¶textæ–‡æœ¬é•¿åº¦,éœ€è¦æ”¹ä¸ºåˆ†å¥å‘é€
            # data_obj['data']['text'] = text
            data_obj['data']['text'] = ' '
        if audio is not None:
            # å¯¹éŸ³é¢‘æ•°æ®è¿›è¡Œbase64ç¼–ç 
            audiob64 = base64.b64encode(audio).decode()
            # print(audiob64)
            data_obj['data']['audio'] = {
                "samplerate": self.audio_samplerate,
                "bits": 16, 
                "channels": self.audio_channels, 
                "format": self.audio_format,
                "buff": audiob64
            }
        return data_obj


    def create_voice_type_msg(self, voice_type: dict):
        """åˆ›å»ºvoice_typeæ¶ˆæ¯
        Args:
            voice_type æ•°æ® 
        """
        data_obj = {
            "node": "tts",  
            "topic": "tts/voice_type",
            "type": "json",
            "data": voice_type
        }
        return data_obj


    def send_voice_types(self):
        """è¯»å–å¹¶å‘é€æ‰€æœ‰éŸ³è‰²æ¶ˆæ¯
        """
        types = self.tts_config['volc']['voice_types']
        for _ in range(3):  # ç¡®ä¿æ¶ˆæ¯æ”¶åˆ° 
            sleep(0.1)
            for type in types: 
                msg = self.create_voice_type_msg(type)
                # print(msg)
                self.auto_send(msg)
                sleep(0.005)
        logger.info('pub all voice type info.')

    def voice_types_test(self, voice_type_index: int):
        """éŸ³è‰²æ’­æ”¾æµ‹è¯•
        """
        types = self.tts_config['volc']['voice_types']
        print(types)
        if voice_type_index < 0:
            for type in types: 
                self.execute(type['example_text'], type['id'])
        else:
            type = types[voice_type_index]
            self.execute(type['example_text'], type['id'])


    def _process_audio_frame(self, audio: bytes, flush=False):
        """å¤„ç†éŸ³é¢‘æ•°æ®
        1. æ•°æ®å¸§å¤„ç†,é™åˆ¶å¸§é•¿
        Args:
            audio:  éŸ³é¢‘æ•°æ® 
            flush:  æ˜¯å¦æ¸…ç©ºç¼“å†²åŒºå‰©ä½™æ•°æ®
        Returns:
            frames: éŸ³é¢‘æ•°æ®å¸§åˆ—è¡¨ï¼Œå«nå¸§æ•°æ®
        """
        frames = []
        self._audio_frame_buff += audio

        # æ¯æ¬¡å¾ªç¯å¤„ç†ä¸€å¸§é•¿åº¦çš„éŸ³é¢‘æ•°æ®
        while len(self._audio_frame_buff) >= self._audio_frame_length:
            # ä»éŸ³é¢‘ç¼“å†²åŒºä¸­å–å‡ºä¸€å¸§é•¿åº¦çš„æ•°æ®
            frame = self._audio_frame_buff[:self._audio_frame_length]
            frames.append(frame)  # å°†å–å‡ºçš„å¸§æ•°æ®åŠ å…¥å¸§åˆ—è¡¨
            self._audio_frame_buff = self._audio_frame_buff[self._audio_frame_length:]  # æ›´æ–°éŸ³é¢‘ç¼“å†²åŒº

        if flush and len(self._audio_frame_buff) > 0:
            # å¦‚æœå¼€å¯äº† flush
            # padding = bytes([0] * (self._audio_frame_length - len(self._audio_frame_buff)))
            frame = self._audio_frame_buff 
            frames.append(frame)
            self._audio_frame_buff = b''  # æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº

        return frames


    def _clear_audio_frame(self):
        """æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
        """
        self._audio_frame_buff = b''


    def send_response_msg(self, msg: str):
        """å¤„ç†å’Œå‘é€TTSå“åº”ç»“æœ
        Args:
            msg          å¾…å‘é€çš„æ¶ˆæ¯
        """
        ## å¦‚æœèŠå¤©å·²ç»å–æ¶ˆ,åˆ™ä¸å‘é€è¯¥æ¶ˆæ¯
        if self.chat_id <= self.cancel_chat_id:
            logger.info('this chat already cancel, no send reponse msg, chat_id: {}, cancel chat_id: {}'.format(self.chat_id, self.cancel_chat_id))
            return
        self.auto_send(msg)


    def handle_tts_result(self, text: str, end_sentence):
        """å¾ªç¯å¤„ç†TTSå“åº”ç»“æœ
           TODO: å¢åŠ è¶…æ—¶é€€å‡º
        Args:
            text: åˆæˆçš„æ–‡æœ¬
            end_sentence: æ˜¯å¦ä¸ºå°¾å¥
        Returns:
            True åˆæˆæˆåŠŸ  Falseåˆæˆå¤±è´¥(ä¸é‡è¯•) 
        """
        finished = False
        while not finished:
            sleep(0.01)  # ç­‰å¾…n ms
            logger.debug('handle tts result loop.')
            res = self.tts.get_result()
            if res is None:
                continue

            if 'status' not in res:
                logger.warning('tts response invaild.')
                self.tts.connect_close()
                self._clear_audio_frame()
                return False

            # print(2,res)
            if res['status'] == 'DISCONNECT':
                self._clear_audio_frame()
                # è¿›è¡Œè‡ªåŠ¨é‡è¿
                self.tts.auto_connect()
                timeout = 10000
                sleep_time = 0.01
                sleep_count = 0
                while True:
                    sleep(sleep_time)
                    sleep_count += 1
                    res = self.tts.get_result()
                    if res is None:
                        continue
                    if res['status'] == "CONNECTED":
                        logger.info('auto reconnect success.')
                        break
                    if sleep_time*sleep_count > timeout:
                        logger.error('ws auto reconnect fail, timeout.')
                        return False

            if res['status'] != 'REQ_OK':
                logger.info('status is not req_ok, is: {}'.format(res['status']))
                continue

            ret = res['result']
            logger.info("synthesis bytes: {}".format(ret['seq_size']))

            ## è·å–éŸ³é¢‘å¸§
            frames = []
            if ret['status'] == 0:
                logger.info("synthesis start...")
                continue
                # frames = self._process_audio_frame(ret['data'])
            elif ret['status'] == 1:  # åˆæˆä¸­é—´æ®µ 
                frames = self._process_audio_frame(ret['data'])

            elif ret['status'] == 2:   # åˆæˆç»“æŸ
                frames = self._process_audio_frame(ret['data'], flush=True)
                finished = True

            elif ret['status'] == -1:  # åˆæˆå¤±è´¥
                logger.warning("synthesis fail, clear frame buff.")
                self._clear_audio_frame()
                return False
            logger.info('get audio frames: {}'.format(len(frames)))

            # å‘ç”Ÿæ•°æ®å¸§æ—¶é—´é—´éš”(ms)  
            send_dt = 0.005
            ## æ­£å¸¸ç»“æŸ   
            if finished: 
                ## å¾ªç¯å‘é€æ•°æ®å¸§
                for frame in frames[0:-1]:
                    msg = self.create_response_msg(self.chat_id, chat_end=0, seg_end = 0, text=text, audio=frame)
                    self.send_response_msg(msg)
                    sleep(send_dt)
                ## å‘é€å°¾å¸§
                msg = None
                if end_sentence:  ## æœ¬æ¬¡èŠå¤©ç»“æŸ
                    msg = self.create_response_msg(self.chat_id, chat_end=1, seg_end = 1, text=text, audio=frames[-1])
                    # self.tts.connect_close() ## æš‚æ—¶ä¸å…³é—­,æœ‰é—®é¢˜
                else:  ## æœ¬æ®µç»“æŸ
                    msg = self.create_response_msg(self.chat_id, chat_end=0, seg_end = 1, text=text, audio=frames[-1])
                # å‘é€å¸§æ¶ˆæ¯
                self.send_response_msg(msg)
                return True
            else:
                ## å¾ªç¯å‘é€æ•°æ®å¸§
                for frame in frames:
                    msg = self.create_response_msg(self.chat_id, chat_end=0, seg_end = 0, text=text, audio=frame)
                    self.send_response_msg(msg)
                    sleep(send_dt)


    def execute(self, text: str, voice_type=None, operation_type = None, end_sentence = False):
        """æ‰§è¡ŒTTS,å¹¶å‘å¸ƒç»“æœ
        Args:
            text:  è¦åˆæˆçš„æ–‡æœ¬
            voice_type:  è¦é€‰æ‹©çš„éŸ³è‰²
            operation_type   'query' or 'submit' å•æ¬¡è¿”å›æˆ–è€…æµå¼è¿”å› 
            end_sentence: æ˜¯å¦ä¸ºå°¾å¥
        """
        ## å¤„ç†ç©ºæ–‡æœ¬è½¬ä¸ºåˆæ³•æäº¤,æäº¤åˆæˆ
        logger.info('start synthesis: {}'.format(text))
        if text == '' or text == ' ':
            logger.info('empty str, return')
            return
        # è®¾ç½®éŸ³è‰²        
        if voice_type is not None:
            self.tts.set_voice_type(voice_type)
        # è®¾ç½®è¿”å›æ–¹å¼       
        if operation_type is not None:
            self.tts.set_operation_type(operation_type)

        # æäº¤åˆæˆ
        self.tts.execute(text)

        # ç­‰å¾…å¹¶å¤„ç†åˆæˆç»“æœ(é˜»å¡)
        logger.info('synthesis execute, start handing')
        ret = self.handle_tts_result(text, end_sentence)
        if ret == False:  ## åˆæˆå¤±è´¥,æ”¾å¼ƒè¿™æ¬¡åˆæˆæ“ä½œ
            logger.warning('synthesis fail.')
        logger.info('synthesis end.')


    def handle_mq_msg(self, msg: dict):
        """Handles Text-to-Speech (TTS) and Eye Animations.

        Args:
            msg: Received message from RabbitMQ.
        """
        logger.debug("Received MQ message, topic: {}".format(msg['topic']))

        ## Handle Chat Cancel Request
        if msg['topic'] == 'request/cancel':
            self.cancel_chat_id = msg['data']['chat_id']
            logger.info(f'Received cancel signal, chat_id: {self.chat_id}, cancel_chat_id: {self.cancel_chat_id}')
            return

        ## Direct TTS Request (Bypassing Chatbot)
        elif msg['topic'] == 'request/tts':
            self.execute(msg['data']['text'], msg['data'].get('voice_type'))
            return

        ## Process Chatbot Response for TTS & Eye Animation
        elif msg['topic'] == 'chat/answer':
            answer = msg['data']
            answer_text = answer['text']
            self.chat_id = answer['chat_id']

            logger.info(f'Processing TTS for chat_id: {self.chat_id}')

            ## If chat was canceled before processing, ignore
            if self.chat_id <= self.cancel_chat_id:
                logger.info(f'This chat was canceled, skipping TTS, chat_id: {self.chat_id}, cancel_chat_id: {self.cancel_chat_id}')
                self.chat_answers = ''
                return

            # ğŸ”¥ New Feature: Analyze Sentiment for Eye Animations
            sentiment = sentiment_analyzer(answer_text)[0]['label']
            send_emotion_to_eyes(sentiment)

            ## Handle TTS Processing
            if answer['seq'] >= 0:
                # Process direct responses (first `direct_n` messages)
                if answer['seq'] < self.direct_n:
                    self.execute(text=answer_text)
                else:
                    # Merge messages to reduce TTS requests
                    text_bytes_size = len(self.chat_answers.encode('utf-8')) + len(answer_text.encode('utf-8'))
                    logger.info(f'TTS text buffer size: {text_bytes_size}')
                    
                    if text_bytes_size > self._tts_text_bytes_max:
                        self.execute(text=self.chat_answers)
                        self.chat_answers = ''
                    
                    self.chat_answers += answer_text

            else:  # **End of Conversation**
                self.chat_answers += answer_text

                if not self.chat_answers:
                    msg = self.create_response_msg(self.chat_id, chat_end=1, seg_end=1)
                    self.auto_send(msg)
                else:
                    self.execute(text=self.chat_answers, end_sentence=True)

                self.chat_answers = ''


    @staticmethod
    def send_emotion_to_eyes(sentiment):
        """Send emotion-based eye animation to ESP32-S3."""
        emotion = TTSNode.map_emotion_to_eyes(sentiment)
        try:
            ws = websocket.WebSocket()
            ws.connect("ws://<ESP32-IP>:<PORT>")  # Replace with your ESP32â€™s IP and port
            # Send as JSON for consistency with other nodes:
            ws.send(json.dumps({"emotion": emotion}))
            ws.close()
        except Exception as e:
            logger.error("Failed to send emotion to ESP32: {}".format(e))

    @staticmethod
    def map_emotion_to_eyes(sentiment):
        """Map sentiment to ESP32 eye animations."""
        if sentiment == "POSITIVE":
            return "HAPPY"
        elif sentiment == "NEGATIVE":
            return "SAD"
        else:
            return "NEUTRAL"
        
    def launch(self):
        """TTSä¸»ä»»åŠ¡
        """
        ## å¯åŠ¨rabbbitmqä¼ è¾“å­çº¿ç¨‹
        self.transport_start()

        ## å¯åŠ¨tts
        self.tts.launch()

        ## é»˜è®¤è®¾ç½®ä¸ºæµå¼å“åº”
        self.tts.set_operation_type(operation_type='submit')
        # self.execute('è¿™æ˜¯ä¸€æ®µè¯ï¼Œç”¨äºè¯­éŸ³åˆæˆæµ‹è¯•,1+1=2, 3+3=6', operation_type='submit')

        ## å¹¿æ’­éŸ³é¢‘ç±»å‹æ•°æ®
        self.send_voice_types()

        ## éŸ³è‰²åˆæˆè¯­éŸ³æµ‹è¯•
        # self.voice_types_test(-1)

        while not self.node_exit:
            logger.debug('tts main loop.')
            # await asyncio.sleep(0.01)
            sleep(0.01)
            # self.keyboard_control()
            ## è·å–æ¥æ”¶é˜Ÿåˆ—æ•°æ®
            mq_msg = self.auto_read()
            if mq_msg is not None:
                self.handle_mq_msg(mq_msg)


    def test(self):
        self.tts.execute(' è¿™æ˜¯ä¸€æ®µè¯ï¼Œç”¨äºè¯­éŸ³åˆæˆæµ‹è¯•.')
        ## ç­‰å¾…æŸ¥è¯¢åˆæˆç»“æœ
        while True:
            sleep(0.1)
            ret = self.tts.get_result()
            if ret is not None:
                print(ret['status'])


def main(config: dict):
    """å…¥å£å‡½æ•°
    """
    tts_node = TTSNode(config)
    # tts_node.test()
    tts_node.launch()


if __name__=='__main__':
    """APPå…¥å£
    """
    logger.info('tts node start...')

    #è¯»å–é…ç½®æ–‡ä»¶
    if len(sys.argv) < 2:
        logger.error('useage: config_file')
        exit(0)

    config_file = sys.argv[1]
    logger.info('config: %s', config_file)

    with open(config_file, 'r', encoding='utf-8') as load_f:
        config = json.load(load_f)
        logger.info(config)
        # asyncio.run(main(config))
        main(config)
